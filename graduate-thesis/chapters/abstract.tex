\begin{abstract}
  代码克隆检测是软件工程领域的重要任务，如何对源代码进行表征学习决定了对源代码信息抽取程度，进而影响下游任务的检测精度。现有的代码表征学习方法存在对代码结构信息和语义信息利用不充分的问题。基于此，本文提出了一种面向代码克隆检测的多维源代码表征学习方法RLCCD(Code \textbf{R}epresentation \textbf{L}earning for \textbf{C}ode \textbf{C}lone \textbf{D}etection)，构建词法单元Token、抽象语法树AST、程序依赖图PDG三个不同维度的代码表征模型，通过特征融合构建多维特征，实现对代码信息的充分利用。
  
  在词法单元Token维度，针对现有Token方法在模型训练中经常出现的集外词问题，提出基于预训练辅助模型的Token表征学习方法。通过组合Token序列的相邻单元，不断迭代更新词汇表；在Token维度表征阶段使用双向长短期记忆网络BiLSTM模型，从前后两个方向同时捕获序列的语义信息，提高对代码信息的表征能力。
  
  在抽象语法树AST维度，针对现有AST方法将抽象语法树转化为二叉树过程中破坏原有结构，增加树高度，导致模型训练过程中梯度消失的问题，提出基于子树划分的抽象语法树表征学习方法。通过子树划分得到AST序列，利用基于树的卷积神经网络学习得到子树粒度的代码信息，利用双向GRU模型学习得到整个抽象语法树的嵌入表征，从而提高树维度的代码表征能力。

  在程序依赖图PDG维度，针对现有PDG方法将代码片段表征为有向多重图，采用子图匹配算法所消耗的时间、空间开销巨大的问题，提出基于图过滤的程序依赖图表征学习方法。在图表征阶段之前，针对候选程序依赖图对集合进行图过滤减少模型输入规模，提升后续基于图卷积神经网络进行图表征学习的训练效率。

  最后，针对以上三个单维度对代码信息利用不充分的问题，提出基于多模态学习的特征融合方法，通过特征连接Concat、特征加法Add两种方式得到混合特征，实现多维源代码表征学习。为验证本文所提方法RLCCD的有效性，与SourcererCC、ASTNN、CCSharp、SCDetector四种代码克隆工具进行对比试验，RLCCD的准确率、召回率、F1值均达到92\%以上，实验说明RLCCD可以利用Token、AST、PDG 三个维度数据之间的信息互补性，学习到更好的特征表示，代码信息利用率高，有效提高了下游代码克隆检测任务的精度。

\end{abstract}

\begin{abstractEn}

  Code cloning detection is an important task in the field of software engineering. How to represent and learn source code determines the degree of information extraction from source code, which in turn affects the detection accuracy of downstream tasks. The existing code representation learning methods suffer from insufficient utilization of code structure and semantic information. Based on this, this paper proposes a multi-dimensional source code representation learning method for code cloning detection(RLCCD), constructing code representation models with three different dimensions: lexical unit Token, abstract syntax tree AST, and program dependency graph PDG. Through feature fusion, multi-dimensional features are obtained, achieving full utilization of code information.


  In terms of Token dimension, a token representation learning method based on pre trained auxiliary models is proposed to address the common problem of out of set words in existing token methods during model training. By combining adjacent units of the Token sequence, iterating continuously, and updating the vocabulary. In the token dimension representation stage, a bidirectional long short-term memory network BiLSTM model is used to capture the semantic information of the sequence from both the front and back directions simultaneously, improving the degree of representation of code information.

  In terms of AST dimension, a representation learning method for abstract syntax trees based on subtree partitioning is proposed to address the problem of existing AST methods breaking the original structure, increasing tree height, and causing gradient disappearance during model training. Among them, the AST sequence is obtained through subtree partitioning, the code information at the subtree granularity is learned by inputting a tree based convolutional neural network, and the embedding representation of the entire abstract syntax tree is learned by inputting a bidirectional GRU model, thereby improving the code representation ability of the tree dimension.

  In terms of PDG dimension, a graph filtering based program dependency graph representation learning method is proposed to address the significant time and space cost of using subgraph matching algorithms to represent code fragments as directed multiple graphs in existing PDG methods. Before the graph representation stage, filter the set of candidate program dependency graphs to reduce the input size of the model and improve the training efficiency of graph representation learning based on graph convolutional neural networks.

  Finally, in response to the problem of insufficient utilization of code information in the above three dimensions, a feature fusion method based on multimodal learning is proposed, which obtains mixed features through feature concatenation and feature addition, achieving multi-dimensional source code representation learning. To verify the effectiveness of the proposed method RLCCD, a comparative experiment was conducted with four code cloning tools, namely Source rCC, ASTNN, CCSharp, and SCDetector. The results showed that RLCCD can utilize the information complementarity between Token, AST, and PDG dimensions of data to learn better feature representations. The code information utilization rate is high, effectively improving the accuracy of downstream code cloning detection tasks.

\end{abstractEn}
