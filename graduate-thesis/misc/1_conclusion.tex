\begin{conclusion}

表征学习是指学习数据的表示，使其在构建分类器或其他预测因子时更容易提取有用信息。目前代码表征学习方法被用于代码克隆检测、代码搜索、代码补全等多个代码分析任务中，取得了一定的成就。然而，现有的代码表征学习仍然面临着信息利用不充分的问题，如何解决这一难题成为研究热点。

针对上述问题，本文提出了面向代码克隆检测的多维源代码表征学习方法RLCCD，实现对代码信息的充分利用，以更加全面准确与智能化的方式提高代码克隆测试效率。本文主要工作和成果如下：

（1）提出基于预训练辅助模型的Token表征学习

针对目前现有的基于Token的表征学习方法通常将词汇单元规范化，在后续神经网络模型训练过程中，当出现某个词汇在词汇表中没有出现过的难题，提出了一种基于预训练辅助模型的Token表征学习方法。该方法在模型训练之前，通过选取预训练辅助模型从代码语料库中学习基本单元的语法语义信息，
设计了一种相邻单元迭代算法，通过组合Token序列中相邻单元构造新的代码表示单元，不断更新词汇表，从而减少出现集外词问题的概率。在POJ104数据集上的消融实验评估表明，预训练辅助模型生成的词嵌入向量作为下游任务的输入特征，可以提升神经网络模型的检测能力，面向代码克隆检测任务，模型的F1值达到了92.61\%。

（2）提出基于子树划分的抽象语法树表征学习

针对现有的基于树的表征学习方法通常将抽象语法树转换为完整二叉树，可能破坏源代码原有语法结构，增加AST高度，丢失长期上下文信息，削弱了神经网络模型捕捉更真实和复杂语义能力，导致梯度消失的难题，提出了一种基于子树划分的抽象语法树表征学习方法。该方法将每个大型的AST分割成子树序列，并输入基于树的卷积神经网络中生成子树的嵌入，输入双向GRU模型中获得代码片段的结构向量表示。在POJ104数据集上的消融实验评估表明，子树划分方法在代码克隆检测的F1值提升了3.41\%。


（3）提出基于图过滤的程序依赖图表征学习

针对现有的基于图的表征学习方法通常将程序表征为有向多重图，继而采用图匹配算法将图中的控制流和数据流编码为一个紧凑的语义特征矩阵，矩阵中每个元素都是高维系数特征向量，所消耗的时间、空间开销巨大的难题，提出了一种基于图过滤的程序依赖图表征学习方法。该方法通过设计一个基于候选程序依赖图对的图过滤算法，减少候选图对的规模，提高后续模型的训练能力。具体的，通过PDG图结构化简、规模过滤、非同构判断、数值特征过滤四个步骤进行过滤，从而减少候选PDG对规模。在POJ104数据集上的消融实验评估表明，经过过滤后的PDG对占原来PDG对数的比例大致在15\%以下，能够有效减少时间、空间开销，提高代码克隆检测准确率。


（4）实现了面向代码克隆检测的多维源代码表征学习方法RLCCD

针对单个维度对代码信息利用不充分的问题，提出了基于多模态学习的特征融合方法，通过融合Token、AST、PDG三个维度的代码特征，采用Concat、Add两种不同的特征融合方法，从多维数据中学到更好的特征表示。同时，选取了代码克隆检测领域常见的基准集POJ104进行实验验证，并与现有开源的SourcererCC\cite{7886988}、ASTNN\cite{8812062}、CCSharp\cite{9286111}、SCDetector\cite{10.1145/3324884.3416562}方法进行比较，实验结果验证了RLCCD的可行性和有效性。

虽然本文所提出的面向代码克隆检测的多维源代码表征学习方法在现有的数据上表现良好，但是尚处于初步研究阶段，未来可以从以下几个方面展开进一步的研究。（1）本文提出的表征学习方法仅仅针对C语言进行了代码克隆检测任务实现，未来可以在此基础上针对不同的编程语言(Python、Java等)开展实验验证，进一步验证该方法的扩展性。（2）本文基于多模态表征学习的特征融合方法虽然在实验准确率上有所提升，但提升效果不明显。目前选取的特征融合方法只选取了Concat、Add两种，这不一定是最佳方法，未来工作中可以尝试其他特征融合方法，甚至针对不同维度的特征向量进行权重赋值，并尝试不同的网络模型结构，进一步提升该方法的效率。（3）目前现有的代码表征质量的评价标准没有统一，现有的工作都是基于具体的代码分析任务进行评价的\cite{张祥平_2011}。不同的分类任务中存在多种不同的指标，这种基于具体任务的结果来判断代码表征质量优劣的方式，并不是直接对表征向量的质量进行衡量。未来的工重点研究如何构建代码表征数据集，并在统一的评价标准上进行方法比较。

\end{conclusion}
